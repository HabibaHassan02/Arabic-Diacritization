{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, AdamW, AutoModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences with diacritics: ['قَوْلُهُ أَوْ قَطَعَ الْأَوَّلُ يَدَهُ إلَخْ قَالَ الزَّرْكَشِيُّ ابْنُ عَرَفَةَ قَوْلُهُ بِلَفْظٍ يَقْتَضِيه كَإِنْكَارِ غَيْرِ حَدِيثٍ بِالْإِسْلَامِ وُجُوبَ مَا عُلِمَ وُجُوبُهُ مِنْ الدِّينِ ضَرُورَةً كَإِلْقَاءِ مُصْحَفٍ بِقَذَرٍ وَشَدِّ زُنَّارٍ ابْنُ عَرَفَةَ قَوْلُ ابْنِ شَاسٍ أَوْ بِفِعْلٍ يَتَضَمَّنُهُ هُوَ كَلُبْسِ الزُّنَّارِ وَإِلْقَاءِ الْمُصْحَفِ فِي صَرِيحِ النَّجَاسَةِ وَالسُّجُودِ لِلصَّنَمِ وَنَحْوِ ذَلِكَ وَسِحْرٍ مُحَمَّدٌ قَوْلُ مَالِكٍ وَأَصْحَابِهِ أَنَّ السَّاحِرَ كَافِرٌ بِاَللَّهِ تَعَالَى قَالَ مَالِكٌ هُوَ كَالزِّنْدِيقِ إذَا عَمِلَ السِّحْرَ بِنَفْسِهِ قُتِلَ وَلَمْ يُسْتَتَبْ', 'قَوْلُهُ لِعَدَمِ مَا تَتَعَلَّقُ إلَخْ أَيْ الْوَصِيَّةُ قَوْلُهُ مَا مَرَّ أَيْ قُبَيْلَ قَوْلِ الْمَتْنِ لَغَتْ وَلَوْ اقْتَصَرَ عَلَى أَوْصَيْت لَهُ بِشَاةٍ أَوْ أَعْطُوهُ شَاةً وَلَا غَنَمَ لَهُ عِنْدَ الْمَوْتِ هَلْ تَبْطُلُ الْوَصِيَّةُ أَوْ يُشْتَرَى لَهُ شَاةٌ وَيُؤْخَذُ مِنْ قَوْلِهِ الْآتِي كَمَا لَوْ لَمْ يَقُلْ مِنْ مَالِي وَلَا مِنْ غَنَمِي أَنَّهَا لَا تَبْطُلُ  وَعِبَارَةُ الْكَنْزِ وَلَوْ لَمْ يَقُلْ مِنْ مَالِي وَلَا مِنْ غَنَمِي لَمْ يَتَعَيَّنْ غَنَمُهُ إنْ كَانَتْ انْتَهَتْ ا ه سم قَوْلُهُ فَيُعْطَى وَاحِدَةً مِنْهَا إلَخْ كَمَا لَوْ كَانَتْ مَوْجُودَةً عِنْدَ الْوَصِيَّةِ وَالْمَوْتِ  وَلَا يَجُوزُ أَنْ يُعْطَى وَاحِدَةً مِنْ غَيْرِ غَنَمِهِ فِي الصُّورَتَيْنِ وَإِنْ تَرَاضَيَا  لِأَنَّهُ صُلْحٌ عَلَى مَجْهُولٍ مُغْنِي وَنِهَايَةٌ قَالَ ع ش قَوْلُهُ وَاحِدَةً مِنْهَا أَيْ كَامِلَةً  وَلَا يَجُوزُ أَنْ يُعْطَى نِصْفَيْنِ مِنْ شَاتَيْنِ  لِأَنَّهُ لَا يُسَمَّى شَاةً وَقَوْلُهُ وَلَا يَجُوزُ أَنْ يُعْطَى وَاحِدَةً مِنْ غَيْرِ غَنَمِهِ وَيَنْبَغِي أَنْ يُقَالَ مِثْلُ ذَلِكَ فِي الْأَرِقَّاءِ ا ه', 'وَحَيَوَانٌ غَيْرُ مَوْجُودٍ', 'فَائِدَةٌ قَالَ بَعْضُهُمْ يُؤْخَذُ مِنْ شَرْطِ تَمَامِ الْمِلْكِ عَدَمُ زَكَاةِ حُلِيِّ الْكَعْبَةِ وَالْمَسَاجِدِ مِنْ قَنَادِيلَ وَعَلَائِقَ وَصَفَائِحِ أَبْوَابٍ', 'وَقَوْلُهُ لَزِمَتْهُ لِمَا قُلْنَا يُرِيدُ قَوْلَهُ  لِأَنَّ الْجَمْعَ بَيْنَهُمَا مَشْرُوعٌ فِي حَقِّ الْآفَاقِيِّ']\n",
      "Sentences without diacritics: ['قوله أو قطع الأول يده إلخ قال الزركشي ابن عرفة قوله بلفظ يقتضيه كإنكار غير حديث بالإسلام وجوب ما علم وجوبه من الدين ضرورة كإلقاء مصحف بقذر وشد زنار ابن عرفة قول ابن شاس أو بفعل يتضمنه هو كلبس الزنار وإلقاء المصحف في صريح النجاسة والسجود للصنم ونحو ذلك وسحر محمد قول مالك وأصحابه أن الساحر كافر بالله تعالى قال مالك هو كالزنديق إذا عمل السحر بنفسه قتل ولم يستتب', 'قوله لعدم ما تتعلق إلخ أي الوصية قوله ما مر أي قبيل قول المتن لغت ولو اقتصر على أوصيت له بشاة أو أعطوه شاة ولا غنم له عند الموت هل تبطل الوصية أو يشترى له شاة ويؤخذ من قوله الآتي كما لو لم يقل من مالي ولا من غنمي أنها لا تبطل  وعبارة الكنز ولو لم يقل من مالي ولا من غنمي لم يتعين غنمه إن كانت انتهت ا ه سم قوله فيعطى واحدة منها إلخ كما لو كانت موجودة عند الوصية والموت  ولا يجوز أن يعطى واحدة من غير غنمه في الصورتين وإن تراضيا  لأنه صلح على مجهول مغني ونهاية قال ع ش قوله واحدة منها أي كاملة  ولا يجوز أن يعطى نصفين من شاتين  لأنه لا يسمى شاة وقوله ولا يجوز أن يعطى واحدة من غير غنمه وينبغي أن يقال مثل ذلك في الأرقاء ا ه', 'وحيوان غير موجود', 'فائدة قال بعضهم يؤخذ من شرط تمام الملك عدم زكاة حلي الكعبة والمساجد من قناديل وعلائق وصفائح أبواب', 'وقوله لزمته لما قلنا يريد قوله  لأن الجمع بينهما مشروع في حق الآفاقي']\n"
     ]
    }
   ],
   "source": [
    "def read_sentences(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        sentences = [line.strip() for line in file.readlines()]\n",
    "    return sentences\n",
    "\n",
    "file_path_with_diacritics = 'sentences_with_diacritics.txt'\n",
    "file_path_without_diacritics = 'sentences_without_diacritics.txt'\n",
    "\n",
    "list_of_sentences_with_diacritics = read_sentences(file_path_with_diacritics)\n",
    "list_of_sentences_without_diacritics = read_sentences(file_path_without_diacritics)\n",
    "\n",
    "print(\"Sentences with diacritics:\", list_of_sentences_with_diacritics[:5])\n",
    "print(\"Sentences without diacritics:\", list_of_sentences_without_diacritics[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"asafaya/bert-base-arabic\"\n",
    "tokenizer= AutoTokenizer.from_pretrained(model_name)\n",
    "model= AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_embeddings(text):\n",
    "    tokens= tokenizer(text,return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    model_output= model(**tokens)\n",
    "\n",
    "    return model_output.last_hidden_state.detach().numpy()\n",
    "\n",
    "auto_sentences_embeddings=[get_embeddings(sentence) for sentence in list_of_string_sentences]\n",
    "\n",
    "print(len(auto_sentences_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"asafaya/bert-base-arabic\")\n",
    "model = AutoModel.from_pretrained(\"asafaya/bert-base-arabic\")\n",
    "\n",
    "def get_embeddings(text):\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    model_output = model(**tokens)\n",
    "\n",
    "    return model_output.last_hidden_state.detach().numpy()\n",
    "\n",
    "# Assuming list_of_string_sentences is a list of undiacritized sentences\n",
    "undiacritized_sentences = list_of_string_sentences\n",
    "\n",
    "# Create a list of tuples, where each tuple contains an undiacritized sentence and its diacritized version\n",
    "paired_sentences = [(undiacritized_sentence, diacritized_sentence) for undiacritized_sentence, diacritized_sentence in zip(undiacritized_sentences, diacritized_sentences)]\n",
    "\n",
    "# Get embeddings for each paired sentence\n",
    "paired_sentences_embeddings = [(get_embeddings(undiacritized_sentence), diacritized_sentence) for undiacritized_sentence, diacritized_sentence in paired_sentences]\n",
    "\n",
    "print(len(paired_sentences_embeddings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sample data (replace with your actual data)\n",
    "train_data = [(\"سلام\", \"سَلام\"), (\"مرحبا\", \"مَرحبًا\"), ...]\n",
    "dev_data = [(\"مرحبا\", \"مَرحبًا\"), ...]\n",
    "test_data = [(\"أهلا\", \"\"), ...]\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"asafaya/bert-base-arabic\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=len(tokenizer))\n",
    "\n",
    "# Tokenize and encode data\n",
    "train_encodings = tokenizer(train_data, return_tensors=\"pt\", padding=\"max_length\", truncation=True)\n",
    "dev_encodings = tokenizer(dev_data, return_tensors=\"pt\", padding=\"max_length\", truncation=True)\n",
    "test_encodings = tokenizer(test_data, return_tensors=\"pt\", padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Extract labels from encoded data\n",
    "train_labels = torch.tensor([[label_ids] for label_ids in tokenizer(train_data[1], return_tensors=\"pt\")[\"input_ids\"]])\n",
    "dev_labels = torch.tensor([[label_ids] for label_ids in tokenizer(dev_data[1], return_tensors=\"pt\")[\"input_ids\"]])\n",
    "\n",
    "# Fine-tune the model\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "for epoch in range(3):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(**train_encodings, labels=train_labels)\n",
    "    loss = outputs.loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Evaluate on dev set\n",
    "with torch.no_grad():\n",
    "    outputs = model(**dev_encodings, labels=dev_labels)\n",
    "    # Process outputs for evaluation\n",
    "\n",
    "# Test the model on the test set\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(**test_encodings)\n",
    "    # Process test_outputs for testing\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
