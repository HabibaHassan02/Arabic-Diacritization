{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Preprocessing :\n",
    "define characters accepted and tashkeel accepted and remove from the training set any tashkeel and unwanted characters (eg. brackets, numbers... etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pyarabic.araby as araby\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import tensorflow as tf\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Embedding, LSTM, Dense, SpatialDropout1D\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "18515271\n"
     ]
    }
   ],
   "source": [
    "arabicDictionary=['ى', 'ع', 'ظ', 'ح', 'ر', 'س', 'ي', 'ش', 'ض', 'ق', ' ', 'ث', 'ل', 'ص', 'ط', 'ك', 'آ', 'م', 'ا', 'إ', 'ه', 'ز', 'ء', 'أ', 'ف', 'ؤ', 'غ', 'ج', 'ئ', 'د', 'ة', 'خ', 'و', 'ب', 'ذ', 'ت', 'ن']\n",
    "punctuations = [\"،\", \":\", \"؛\", \"-\", \"؟\"]\n",
    "#reading the training dataset\n",
    "f = open(r\"train.txt\", \"r\",encoding=\"utf-8\").read()\n",
    "print(type(f))\n",
    "print(len(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanDataFromNonArabicLetters(data):\n",
    "    #regex to keep arabic letters only and remove any other character (eg. brackets, numbers ...etc)\n",
    "    characters_regex =r'[\\s\\.\\u0600-\\u06ff\\u0750-\\u077f\\ufb50-\\ufbc1\\ufbd3-\\ufd3f\\ufd50-\\ufd8f\\ufd50-\\ufd8f\\ufe70-\\ufefc\\uFDF0-\\uFDFD]+'\n",
    "    processedData = re.findall(characters_regex,data)\n",
    "    processedData = \" \".join(processedData)\n",
    "    processedData = re.sub(r\"\\s+\",\" \" ,processedData) #substitute many spaces with one space only\n",
    "    return processedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17997403\n"
     ]
    }
   ],
   "source": [
    "processedData=cleanDataFromNonArabicLetters(f)\n",
    "print(len(processedData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeDiacratics(processedData):\n",
    "    without_diacritics= araby.strip_diacritics(processedData)\n",
    "    return without_diacritics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10711561\n"
     ]
    }
   ],
   "source": [
    "without_diacritics = removeDiacratics(processedData)\n",
    "print(len(without_diacritics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take the procrssed text and separate it into sentences\n",
    "def generateListsWithDiacraticsandWithout(with_diacratics, without_diacritics):\n",
    "    #---------------------Preprocessing of words with diacratics------------\n",
    "\n",
    "    #generate longStringSplited which is the list of procrssed text without brackets and numbers and dots \n",
    "    #the rest of the punctuation still there\n",
    "    longStringWithDecimalPoint=re.sub(r\"\\n\", ' ', with_diacratics) #string of data with diacratics removed endlines from it\n",
    "    for element in punctuations:\n",
    "        longStringWithDecimalPoint=re.sub(element, '', longStringWithDecimalPoint) #remove punctuations from the string\n",
    "\n",
    "    longStringSplited=longStringWithDecimalPoint.split('.') #split the string by dots (segment sentences) and make list of them\n",
    "    longString=' '.join(longStringSplited)  #long string without decimal points\n",
    "\n",
    "    #-------------------------------------\n",
    "\n",
    "    #---------------------Preprocessing of words without diacratics------------\n",
    "    without_diacratics_longStringWithDecimals=re.sub(r\"\\n\", ' ', without_diacritics) #string of data without diacratics removed endlines from it\n",
    "    for element in punctuations:\n",
    "        without_diacratics_longStringWithDecimals=re.sub(element, '', without_diacratics_longStringWithDecimals) #remove punctuations from the string\n",
    "\n",
    "    longStringSplited_withoutDiacratics=without_diacratics_longStringWithDecimals.split('.') #split the string by dots (segment sentences) and make list of them\n",
    "    longString_withoutDiacratics=' '.join(longStringSplited_withoutDiacratics)  #long string without decimal points\n",
    "\n",
    "    #-------------------------------------------------------------------------\n",
    "\n",
    "    list_of_sentences=[]\n",
    "    for line in longStringSplited_withoutDiacratics: #list of lists of sentences splitted in words without diacratics (used in embeddings)\n",
    "        list_of_sentences.append(line.split(\" \"))\n",
    "    \n",
    "\n",
    "    # now the variable called longString has a single string with all the processed words in it \n",
    "    listOfwordsWith_Diacritics=list()\n",
    "    listOfwordsWith_NoDiacritics=list()\n",
    "\n",
    "    listOfwordsWith_Diacritics=re.sub(r\"\\s+\", ' ', longString)\n",
    "    listOfwordsWith_Diacritics=listOfwordsWith_Diacritics.split(\" \")\n",
    "\n",
    "    listOfwordsWith_NoDiacritics=re.sub(r\"\\s+\", ' ', longString_withoutDiacratics)\n",
    "    listOfwordsWith_NoDiacritics=listOfwordsWith_NoDiacritics.split(\" \")\n",
    "\n",
    "    return list_of_sentences,listOfwordsWith_Diacritics,listOfwordsWith_NoDiacritics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_sentences,listOfwordsWith_Diacritics,listOfwordsWith_NoDiacritics= generateListsWithDiacraticsandWithout(processedData, without_diacritics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40836\n",
      "2102054\n",
      "2102054\n",
      "['أَوْ', 'سَيِّدُهَا', 'فِي', 'ذَلِكَ', 'جَازَ', 'لِأَنَّ', 'لَهُ', 'غَرَضًا', 'فِي', 'تَزَيُّنِهَا', 'لَهُ', 'كَمَا', 'فِي', 'الرَّوْضَةِ', 'وَهُوَ', 'الْأَوْجَهُ', 'وَإِنْ', 'جَرَى', 'فِي', 'التَّحْقِيقِ', 'عَلَى', 'خِلَافِ', 'ذَلِكَ', 'فِي', 'الْوَصْلِ', 'وَالْوَشْرِ', 'فَأَلْحَقَهُمَا', 'بِالْوَشْمِ', 'فِي', 'الْمَنْعِ', 'مُطْلَقًا', 'وَيُكْرَهُ', 'أَنْ', 'يَنْتِفَ', 'الشَّيْبَ', 'مِنْ', 'الْمَحَلِّ', 'الَّذِي', 'لَا', 'يُطْلَبُ', 'مِنْهُ', 'إزَالَةُ', 'شَعْرِهِ', 'وَيُسَنُّ', 'خَضْبُهُ', 'بِالْحِنَّاءِ', 'وَنَحْوِهِ', 'وَيُسَنُّ', 'لِلْمَرْأَةِ', 'الْمُزَوَّجَةِ', 'وَالْمَمْلُوكَةِ', 'خَضْبُ', 'كَفِّهَا', 'وَقَدَمِهَا', 'بِذَلِكَ', 'تَعْمِيمًا', 'لِأَنَّهُ', 'زِينَةٌ', 'وَهِيَ', 'مَطْلُوبَةٌ', 'مِنْهَا', 'لِحَلِيلِهَا', 'أَمَّا', 'النَّقْشُ', 'وَالتَّطْرِيفُ', 'فَلَا', 'يُسَنُّ', 'وَخَرَجَ', 'بِالْمُزَوَّجَةِ', 'وَالْمَمْلُوكَةِ', 'غَيْرُهُمَا', 'فَيُكْرَهُ', 'لَهُ', 'وَبِالْمَرْأَةِ', 'الرَّجُلُ', 'وَالْخُنْثَى', 'فَيَحْرُمُ', 'الْخِضَابُ', 'عَلَيْهِمَا', 'إلَّا', 'لِعُذْرٍ', 'نِهَايَةٌ', 'وَمُغْنِي', 'قَالَ', 'ع', 'ش', 'قَوْلُهُ', 'م', 'ر', 'وَيَحْرُمُ', 'عَلَى', 'الْمَرْأَةِ', 'خَرَجَ', 'بِالْمَرْأَةِ', 'غَيْرُهَا', 'مِنْ', 'ذَكَرٍ', 'وَأُنْثَى', 'صَغِيرَيْنِ', 'فَيَجُوزُ']\n",
      "['أو', 'سيدها', 'في', 'ذلك', 'جاز', 'لأن', 'له', 'غرضا', 'في', 'تزينها', 'له', 'كما', 'في', 'الروضة', 'وهو', 'الأوجه', 'وإن', 'جرى', 'في', 'التحقيق', 'على', 'خلاف', 'ذلك', 'في', 'الوصل', 'والوشر', 'فألحقهما', 'بالوشم', 'في', 'المنع', 'مطلقا', 'ويكره', 'أن', 'ينتف', 'الشيب', 'من', 'المحل', 'الذي', 'لا', 'يطلب', 'منه', 'إزالة', 'شعره', 'ويسن', 'خضبه', 'بالحناء', 'ونحوه', 'ويسن', 'للمرأة', 'المزوجة', 'والمملوكة', 'خضب', 'كفها', 'وقدمها', 'بذلك', 'تعميما', 'لأنه', 'زينة', 'وهي', 'مطلوبة', 'منها', 'لحليلها', 'أما', 'النقش', 'والتطريف', 'فلا', 'يسن', 'وخرج', 'بالمزوجة', 'والمملوكة', 'غيرهما', 'فيكره', 'له', 'وبالمرأة', 'الرجل', 'والخنثى', 'فيحرم', 'الخضاب', 'عليهما', 'إلا', 'لعذر', 'نهاية', 'ومغني', 'قال', 'ع', 'ش', 'قوله', 'م', 'ر', 'ويحرم', 'على', 'المرأة', 'خرج', 'بالمرأة', 'غيرها', 'من', 'ذكر', 'وأنثى', 'صغيرين', 'فيجوز']\n"
     ]
    }
   ],
   "source": [
    "print(len(list_of_sentences))\n",
    "print(len(listOfwordsWith_NoDiacritics))\n",
    "print(len(listOfwordsWith_Diacritics))\n",
    "print(listOfwordsWith_Diacritics[2101000:2101100])\n",
    "print(listOfwordsWith_NoDiacritics[2101000:2101100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDiacraticsList(listOfwordsWith_Diacritics):\n",
    "    #now that we have two separated lists we need to get the diacritics list \n",
    "\n",
    "\n",
    "    listofDiacritrcs_ToWord=list()\n",
    "    temp=list()\n",
    "    counter=0\n",
    "    for word in listOfwordsWith_Diacritics:\n",
    "        while counter<len(word):\n",
    "            if word[counter] in arabicDictionary: #checking if the character is a letter\n",
    "                if (counter+1)<len(word):\n",
    "                    #checking if the next character is also a letter, then that means that the diacritics of the current letter is none so add empty string to the list\n",
    "                    if word[counter +1] in arabicDictionary: \n",
    "                        temp.append(\"\")\n",
    "                        counter+=1\n",
    "                        continue\n",
    "                counter+=1 #if it is the end of the word (no more letters) or the next character is a diacritics -> continue looping\n",
    "                continue\n",
    "            else:\n",
    "                if (counter+1)<len(word):\n",
    "                    if word[(counter+1)] not in arabicDictionary: #if the current and the next characters are diacritics, add them together in the list\n",
    "                        temp.append(word[counter]+word[counter+1])\n",
    "                        counter+=2\n",
    "                        continue\n",
    "                temp.append(word[counter]) #if the current character only is the diacritics add it to the list\n",
    "                counter+=1    \n",
    "        listofDiacritrcs_ToWord.append(temp.copy())     \n",
    "        temp.clear() \n",
    "        counter=0\n",
    "    return listofDiacritrcs_ToWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "listofDiacritrcs_ToWord= generateDiacraticsList(listOfwordsWith_Diacritics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2102054\n",
      "الْأَوَّلُ\n",
      "الأول\n",
      "['', 'ْ', 'َ', 'َّ', 'ُ']\n",
      " ْ َ َّ ُ\n",
      "[['َ', 'ْ', 'ُ', 'ُ'], ['َ', 'ْ'], ['َ', 'َ', 'َ'], ['', 'ْ', 'َ', 'َّ', 'ُ'], ['َ', 'َ', 'ُ'], ['', 'َ', 'ْ'], ['َ', '', 'َ'], ['', '', 'َّ', 'ْ', 'َ', 'ِ', 'ُّ'], ['', 'ْ', 'ُ'], ['َ', 'َ', 'َ', 'َ'], ['َ', 'ْ', 'ُ', 'ُ'], ['ِ', 'َ', 'ْ', 'ٍ'], ['َ', 'ْ', 'َ', 'ِ', ''], ['َ', 'ِ', 'ْ', 'َ', '', 'ِ'], ['َ', 'ْ', 'ِ'], ['َ', 'ِ', '', 'ٍ'], ['ِ', '', 'ْ', 'ِ', 'ْ', 'َ', '', 'ِ'], ['ُ', 'ُ', '', 'َ'], ['َ'], ['ُ', 'ِ', 'َ'], ['ُ', 'ُ', '', 'ُ', 'ُ'], ['ِ', 'ْ'], ['', '', 'ِّ', '', 'ِ'], ['َ', 'ُ', '', 'َ', 'ً'], ['َ', 'ِ', 'ْ', 'َ', '', 'ِ'], ['ُ', 'ْ', 'َ', 'ٍ'], ['ِ', 'َ', 'َ', 'ٍ'], ['َ', 'َ', 'ِّ'], ['ُ', 'َّ', '', 'ٍ'], ['', 'ْ', 'ُ'], ['َ', 'َ', 'َ', 'َ'], ['َ', 'ْ', 'ُ'], ['', 'ْ', 'ِ'], ['َ', '', 'ٍ'], ['َ', 'ْ'], ['ِ', 'ِ', 'ْ', 'ٍ'], ['َ', 'َ', 'َ', 'َّ', 'ُ', 'ُ'], ['ُ', 'َ'], ['َ', 'ُ', 'ْ', 'ِ'], ['', '', 'ُّ', 'َّ', '', 'ِ'], ['َ', 'ِ', 'ْ', 'َ', '', 'ِ'], ['', 'ْ', 'ُ', 'ْ', 'َ', 'ِ'], ['ِ'], ['َ', 'ِ', '', 'ِ'], ['', '', 'َّ', 'َ', '', 'َ', 'ِ'], ['َ', '', '', 'ُّ', 'ُ', '', 'ِ'], ['ِ', '', 'َّ', 'َ', 'ِ'], ['َ', 'َ', 'ْ', 'ِ'], ['َ', 'ِ', 'َ'], ['َ', 'ِ', 'ْ', 'ٍ'], ['ُ', 'َ', 'َّ', 'ٌ'], ['َ', 'ْ', 'ُ'], ['َ', '', 'ِ', 'ٍ'], ['َ', 'َ', 'ْ', 'َ', '', 'ِ', 'ِ'], ['َ', 'َّ'], ['', '', 'َّ', '', 'ِ', 'َ'], ['َ', '', 'ِ', 'ٌ'], ['ِ', 'َ', '', 'َّ', 'ِ'], ['َ', 'َ', '', 'َ'], ['َ', '', 'َ'], ['َ', '', 'ِ', 'ٌ'], ['ُ', 'َ'], ['َ', '', '', 'ِّ', 'ْ', 'ِ', '', 'ِ'], ['', 'َ'], ['َ', 'ِ', 'َ'], ['', '', 'ِّ', 'ْ', 'َ'], ['ِ', 'َ', 'ْ', 'ِ', 'ِ'], ['ُ', 'ِ', 'َ'], ['َ', 'َ', 'ْ'], ['ُ', 'ْ', 'َ', 'َ', 'ْ'], ['َ', 'ْ', 'ُ', 'ُ'], ['ِ', 'َ', 'َ', 'ِ'], ['َ'], ['َ', 'َ', 'َ', 'َّ', 'ُ'], ['', 'َ', 'ْ'], ['َ', 'ْ'], ['', 'ْ', 'َ', 'ِ', 'َّ', 'ُ'], ['َ', 'ْ', 'ُ', 'ُ'], ['َ'], ['َ', 'َّ'], ['َ', 'ْ'], ['ُ', 'َ', 'ْ', 'َ'], ['َ', 'ْ', 'ِ'], ['', 'ْ', 'َ', 'ْ', 'ِ'], ['َ', 'َ', 'ْ'], ['َ', 'َ', 'ْ'], ['', 'ْ', 'َ', 'َ', 'َ'], ['َ', 'َ'], ['َ', 'ْ', 'َ', 'ْ'], ['َ', 'ُ'], ['ِ', 'َ', '', 'ٍ'], ['َ', 'ْ'], ['َ', 'ْ', 'ُ', '', 'ُ'], ['َ', '', 'ً'], ['َ', 'َ'], ['َ', 'َ', 'َ'], ['َ', 'ُ'], ['ِ', 'ْ', 'َ'], ['', 'ْ', 'َ', 'ْ', 'ِ'], ['َ', 'ْ']]\n"
     ]
    }
   ],
   "source": [
    "print(len(listofDiacritrcs_ToWord))\n",
    "print(listOfwordsWith_Diacritics[3])\n",
    "print(listOfwordsWith_NoDiacritics[3])\n",
    "print(listofDiacritrcs_ToWord[3])\n",
    "print(\" \".join(listofDiacritrcs_ToWord[3]))\n",
    "print(listofDiacritrcs_ToWord[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vecmodel(input):\n",
    "    # Train Word2Vec model\n",
    "    Word2Vec_model = Word2Vec(input, vector_size=100, window=5, min_count=1, workers=4, sg=0)\n",
    "    Word2Vec_model.train(input,total_examples=len(listOfwordsWith_NoDiacritics),epochs=10)\n",
    "    word_embeddings = {word: Word2Vec_model.wv[word] for word in Word2Vec_model.wv.index_to_key}\n",
    "    return Word2Vec_model, word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings_model, word_embeddings= word2vecmodel(list_of_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-Building the LSTM model for character level classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatingXandYtrain(listofDiacritrcs_ToWord,listOfwordsWith_NoDiacritics):\n",
    "    for i in range(len(listofDiacritrcs_ToWord)):\n",
    "        listofDiacritrcs_ToWord[i] = \" \".join(listofDiacritrcs_ToWord[i])\n",
    "    Y_train= np.array([listofDiacritrcs_ToWord],dtype=object).T\n",
    "    X_train = np.array([listOfwordsWith_NoDiacritics],dtype=object)\n",
    "    print(str(X_train.shape))\n",
    "    print(str(Y_train.shape))\n",
    "    return X_train,Y_train\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2102054)\n",
      "(2102054, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train= formatingXandYtrain(listofDiacritrcs_ToWord,listOfwordsWith_NoDiacritics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareForTraining(listOfwordsWith_NoDiacritics,listofDiacritrcs_ToWord):\n",
    "    # Tokenize the input words and diacritics\n",
    "    word_tokenizer = tf.keras.preprocessing.text.Tokenizer(char_level=True, filters='')\n",
    "    word_tokenizer.fit_on_texts(listOfwordsWith_NoDiacritics)\n",
    "    word_sequences = word_tokenizer.texts_to_sequences(listOfwordsWith_NoDiacritics)\n",
    "\n",
    "    diacritic_tokenizer = tf.keras.preprocessing.text.Tokenizer(char_level=True, filters='')\n",
    "    diacritic_tokenizer.fit_on_texts([''.join(d) for d in listofDiacritrcs_ToWord])\n",
    "    diacritic_sequences = diacritic_tokenizer.texts_to_sequences([''.join(d) for d in listofDiacritrcs_ToWord])\n",
    "\n",
    "    # Pad sequences to have the same length\n",
    "    max_len = max(max(len(seq) for seq in word_sequences), max(len(seq) for seq in diacritic_sequences))\n",
    "    return word_tokenizer,diacritic_tokenizer,max_len,word_sequences,diacritic_sequences\n",
    "\n",
    "def trainDiacritics(word_tokenizer,diacritic_tokenizer,max_len,word_sequences,diacritic_sequences):\n",
    "    # Pad sequences to have the same length\n",
    "    padded_word_sequences = pad_sequences(word_sequences, maxlen=max_len, padding='post')\n",
    "    padded_diacritic_sequences = pad_sequences(diacritic_sequences, maxlen=max_len, padding='post')\n",
    "\n",
    "    # Build the LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=len(word_tokenizer.word_index) + 1, output_dim=50, input_length=max_len))\n",
    "    model.add(LSTM(100, return_sequences=True))\n",
    "    model.add(Dense(len(diacritic_tokenizer.word_index) + 1, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(padded_word_sequences, np.expand_dims(padded_diacritic_sequences, -1), epochs=10, batch_size=32)\n",
    "\n",
    "    # Save the model for later use\n",
    "    model.save(\"diacritic_prediction_model.h5\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# Now, you can use the trained model to predict diacritics for new Arabic words\n",
    "def predict_diacritics(model,word_tokenizer, diacritic_tokenizer,max_len, word):\n",
    "    word_sequence = word_tokenizer.texts_to_sequences([word])\n",
    "    padded_word_sequence = pad_sequences(word_sequence, maxlen=max_len, padding='post')\n",
    "    predicted_diacritic_sequence = model.predict(padded_word_sequence)\n",
    "    predicted_diacritic_sequence = np.argmax(predicted_diacritic_sequence, axis=-1)\n",
    "    predicted_diacritic = diacritic_tokenizer.sequences_to_texts(predicted_diacritic_sequence)\n",
    "    return predicted_diacritic[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenizer,diacritic_tokenizer,max_len,word_sequences,diacritic_sequences = prepareForTraining(listOfwordsWith_NoDiacritics,listofDiacritrcs_ToWord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!!! DO NOT RUN THE COMING CELL UNLESS YOU HAVE MADE UPDATES IN THE MODEL\n",
    "you can use the model by calling:\n",
    "### model = load_model('diacritic_prediction_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65690/65690 [==============================] - 919s 14ms/step - loss: 0.1176 - accuracy: 0.9577\n",
      "Epoch 2/10\n",
      "65690/65690 [==============================] - 926s 14ms/step - loss: 0.0918 - accuracy: 0.9656\n",
      "Epoch 3/10\n",
      "65690/65690 [==============================] - 15081s 230ms/step - loss: 0.0885 - accuracy: 0.9666\n",
      "Epoch 4/10\n",
      "65690/65690 [==============================] - 1742s 27ms/step - loss: 0.0869 - accuracy: 0.9671\n",
      "Epoch 5/10\n",
      "65690/65690 [==============================] - 1458s 22ms/step - loss: 0.0860 - accuracy: 0.9674\n",
      "Epoch 6/10\n",
      "65690/65690 [==============================] - 1331s 20ms/step - loss: 0.0853 - accuracy: 0.9676\n",
      "Epoch 7/10\n",
      "65690/65690 [==============================] - 1434s 22ms/step - loss: 0.0849 - accuracy: 0.9677\n",
      "Epoch 8/10\n",
      "65690/65690 [==============================] - 1538s 23ms/step - loss: 0.0845 - accuracy: 0.9678\n",
      "Epoch 9/10\n",
      "65690/65690 [==============================] - 2518s 38ms/step - loss: 0.0843 - accuracy: 0.9679\n",
      "Epoch 10/10\n",
      "65690/65690 [==============================] - 2832s 43ms/step - loss: 0.0840 - accuracy: 0.9679\n"
     ]
    }
   ],
   "source": [
    "model=trainDiacritics(word_tokenizer,diacritic_tokenizer,max_len,word_sequences,diacritic_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('diacritic_prediction_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words 4\n",
      "1/1 [==============================] - 1s 627ms/step\n",
      "ذَهَبَ\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "عَلَيَّ\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "إلَى\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "الَّْشاِطِئ\n",
      "ذَهَبَ عَلَيَّ إلَى الَّْشاِطِئ \n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "# input = \"الذي علم بالقلم\"\n",
    "input= \"ذهب علي إلى الشاطئ\"\n",
    "model = load_model(\"diacritic_prediction_model.h5\")\n",
    "\n",
    "# input = \"قال الزركشي ابن عرفة قوله بلفظ يقتضيه كإنكار غير حديث بالإسلام وجوب ما علم وجوبه من الدين ضرورة كإلقاء مصحف بقذر\"\n",
    "input_word = input.split(' ')\n",
    "word_vectors = [word_embeddings_model.wv[word] for word in input_word if word in word_embeddings_model.wv]\n",
    "# print(word_vectors)\n",
    "outputString=\"\"\n",
    "print(\"number of words\",len(input_word))\n",
    "for word in input_word: \n",
    "  predicted_diacritics1 = predict_diacritics(model,word_tokenizer, diacritic_tokenizer,max_len, word)\n",
    "  #print(predicted_diacritics1.split(' '))\n",
    "  predictedDiacritics=(predicted_diacritics1.split('  '))\n",
    "  temp=list()\n",
    "  for diacrtic in predictedDiacritics:\n",
    "    # print(diacrtic)\n",
    "    # print(len(diacrtic))\n",
    "    if ' ' in diacrtic:\n",
    "      # print(\"after space removel\")\n",
    "      diacrtic=diacrtic.replace(' ','')\n",
    "      # print(diacrtic)\n",
    "      # print(len(diacrtic))\n",
    "      temp.append(diacrtic)\n",
    "      continue\n",
    "    temp.append(diacrtic)\n",
    "  predictedDiacritics=temp.copy()\n",
    "  tempString=\"\"\n",
    "  for i in range(len(word)):\n",
    "    tempString+=word[i]\n",
    "    if i<len(predictedDiacritics):\n",
    "      tempString+=predictedDiacritics[i]\n",
    "  print(tempString)\n",
    "  tempString+=\" \"\n",
    "  outputString+=tempString\n",
    "\n",
    "print(outputString)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
